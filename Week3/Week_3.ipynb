{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l7ecpvGJMiwM",
        "outputId": "802aa1e9-babd-4af5-b698-0bc21c95e81d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing coalesced.cu\n"
          ]
        }
      ],
      "source": [
        "%%writefile coalesced.cu\n",
        "#include <stdio.h>\n",
        "#include <cuda_runtime.h>\n",
        "\n",
        "// Task 1.1: Coalesced Access\n",
        "// Threads access memory consecutively: Thread i reads Data[i]\n",
        "__global__ void coalesced_kernel(float* data, int n) {\n",
        "    int idx = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    if (idx < n) {\n",
        "        // Coalesced read and write\n",
        "        data[idx] = data[idx] * 2.0f;\n",
        "    }\n",
        "}\n",
        "\n",
        "int main() {\n",
        "    int n = 1 << 24; // 16M floats\n",
        "    size_t bytes = n * sizeof(float);\n",
        "    float *d_data;\n",
        "\n",
        "    cudaMalloc(&d_data, bytes);\n",
        "\n",
        "    // Warmup\n",
        "    int blockSize = 256;\n",
        "    int gridSize = (n + blockSize - 1) / blockSize;\n",
        "    coalesced_kernel<<<gridSize, blockSize>>>(d_data, n);\n",
        "    cudaDeviceSynchronize();\n",
        "\n",
        "    // Timing\n",
        "    cudaEvent_t start, stop;\n",
        "    cudaEventCreate(&start); cudaEventCreate(&stop);\n",
        "\n",
        "    cudaEventRecord(start);\n",
        "    coalesced_kernel<<<gridSize, blockSize>>>(d_data, n);\n",
        "    cudaEventRecord(stop);\n",
        "\n",
        "    cudaDeviceSynchronize();\n",
        "    float milliseconds = 0;\n",
        "    cudaEventElapsedTime(&milliseconds, start, stop);\n",
        "\n",
        "    printf(\"Coalesced Access Time: %.3f ms\\n\", milliseconds);\n",
        "    printf(\"Effective Bandwidth: %.2f GB/s\\n\", (2.0f * bytes) / (milliseconds * 1e6));\n",
        "\n",
        "    cudaFree(d_data);\n",
        "    return 0;\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile non_coalesced.cu\n",
        "#include <stdio.h>\n",
        "#include <cuda_runtime.h>\n",
        "\n",
        "// Task 1.2: Non-Coalesced Access (Strided)\n",
        "// Threads access memory with a stride: Thread i reads Data[i * stride]\n",
        "__global__ void strided_kernel(float* data, int n, int stride) {\n",
        "    int idx = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    // Bounds check accounts for the stride to prevent out-of-bounds\n",
        "    if (idx * stride < n) {\n",
        "        // Strided read and write (Performance Killer)\n",
        "        data[idx * stride] = data[idx * stride] * 2.0f;\n",
        "    }\n",
        "}\n",
        "\n",
        "int main() {\n",
        "    int n = 1 << 24; // 16M floats\n",
        "    size_t bytes = n * sizeof(float);\n",
        "    float *d_data;\n",
        "    int stride = 32; // Stride of 32 breaks coalescing completely\n",
        "\n",
        "    cudaMalloc(&d_data, bytes);\n",
        "\n",
        "    // Kernel configuration\n",
        "    int blockSize = 256;\n",
        "    // Grid must cover the *indices*, not the total array size\n",
        "    int num_elements_accessed = n / stride;\n",
        "    int gridSize = (num_elements_accessed + blockSize - 1) / blockSize;\n",
        "\n",
        "    // Timing\n",
        "    cudaEvent_t start, stop;\n",
        "    cudaEventCreate(&start); cudaEventCreate(&stop);\n",
        "\n",
        "    cudaEventRecord(start);\n",
        "    strided_kernel<<<gridSize, blockSize>>>(d_data, n, stride);\n",
        "    cudaEventRecord(stop);\n",
        "\n",
        "    cudaDeviceSynchronize();\n",
        "    float milliseconds = 0;\n",
        "    cudaEventElapsedTime(&milliseconds, start, stop);\n",
        "\n",
        "    printf(\"Non-Coalesced (Stride %d) Time: %.3f ms\\n\", stride, milliseconds);\n",
        "    // Note: We transfer 32x less data, but check the bandwidth utilization!\n",
        "    size_t active_bytes = (n / stride) * sizeof(float);\n",
        "    printf(\"Effective Bandwidth: %.2f GB/s\\n\", (2.0f * active_bytes) / (milliseconds * 1e6));\n",
        "\n",
        "    cudaFree(d_data);\n",
        "    return 0;\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4rcqWdCXQBgG",
        "outputId": "ff80b68e-9789-43af-ca2b-d26bcfbb14a0"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing non_coalesced.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile shared_memory.cu\n",
        "#include <stdio.h>\n",
        "#include <cuda_runtime.h>\n",
        "#include <stdlib.h>\n",
        "\n",
        "#define TILE_WIDTH 32\n",
        "\n",
        "// Baseline: Global Memory Only\n",
        "__global__ void matmul_naive(float *A, float *B, float *C, int N) {\n",
        "    int row = blockIdx.y * blockDim.y + threadIdx.y;\n",
        "    int col = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "\n",
        "    if (row < N && col < N) {\n",
        "        float sum = 0.0f;\n",
        "        for (int k = 0; k < N; k++) {\n",
        "            sum += A[row * N + k] * B[k * N + col];\n",
        "        }\n",
        "        C[row * N + col] = sum;\n",
        "    }\n",
        "}\n",
        "\n",
        "// Optimized: Shared Memory Tiling\n",
        "__global__ void matmul_shared(float *A, float *B, float *C, int N) {\n",
        "    __shared__ float tile_A[TILE_WIDTH][TILE_WIDTH];\n",
        "    __shared__ float tile_B[TILE_WIDTH][TILE_WIDTH];\n",
        "\n",
        "    int row = blockIdx.y * TILE_WIDTH + threadIdx.y;\n",
        "    int col = blockIdx.x * TILE_WIDTH + threadIdx.x;\n",
        "    float sum = 0.0f;\n",
        "\n",
        "    for (int t = 0; t < (N + TILE_WIDTH - 1) / TILE_WIDTH; t++) {\n",
        "        int col_A = t * TILE_WIDTH + threadIdx.x;\n",
        "        int row_B = t * TILE_WIDTH + threadIdx.y;\n",
        "\n",
        "        // Load A tile\n",
        "        if (row < N && col_A < N)\n",
        "            tile_A[threadIdx.y][threadIdx.x] = A[row * N + col_A];\n",
        "        else\n",
        "            tile_A[threadIdx.y][threadIdx.x] = 0.0f;\n",
        "\n",
        "        // Load B tile\n",
        "        if (row_B < N && col < N)\n",
        "            tile_B[threadIdx.y][threadIdx.x] = B[row_B * N + col];\n",
        "        else\n",
        "            tile_B[threadIdx.y][threadIdx.x] = 0.0f;\n",
        "\n",
        "        __syncthreads(); // Wait for load\n",
        "\n",
        "        for (int k = 0; k < TILE_WIDTH; k++) {\n",
        "            sum += tile_A[threadIdx.y][k] * tile_B[k][threadIdx.x];\n",
        "        }\n",
        "\n",
        "        __syncthreads(); // Wait for compute before next load\n",
        "    }\n",
        "\n",
        "    if (row < N && col < N) {\n",
        "        C[row * N + col] = sum;\n",
        "    }\n",
        "}\n",
        "\n",
        "int main() {\n",
        "    int N = 2048; // Large enough to see difference\n",
        "    size_t bytes = N * N * sizeof(float);\n",
        "    printf(\"Matrix Multiplication (N=%d)\\n\", N);\n",
        "\n",
        "    float *d_A, *d_B, *d_C;\n",
        "    cudaMalloc(&d_A, bytes);\n",
        "    cudaMalloc(&d_B, bytes);\n",
        "    cudaMalloc(&d_C, bytes);\n",
        "\n",
        "    // Initialize random data (omitted for brevity, assume populated)\n",
        "\n",
        "    dim3 block(TILE_WIDTH, TILE_WIDTH);\n",
        "    dim3 grid((N + TILE_WIDTH - 1) / TILE_WIDTH, (N + TILE_WIDTH - 1) / TILE_WIDTH);\n",
        "\n",
        "    // Timing Naive\n",
        "    cudaEvent_t start, stop;\n",
        "    cudaEventCreate(&start); cudaEventCreate(&stop);\n",
        "\n",
        "    cudaEventRecord(start);\n",
        "    matmul_naive<<<grid, block>>>(d_A, d_B, d_C, N);\n",
        "    cudaEventRecord(stop);\n",
        "    cudaDeviceSynchronize();\n",
        "\n",
        "    float naive_time = 0;\n",
        "    cudaEventElapsedTime(&naive_time, start, stop);\n",
        "    printf(\"Naive Time: %.3f ms\\n\", naive_time);\n",
        "\n",
        "    // Timing Shared\n",
        "    cudaEventRecord(start);\n",
        "    matmul_shared<<<grid, block>>>(d_A, d_B, d_C, N);\n",
        "    cudaEventRecord(stop);\n",
        "    cudaDeviceSynchronize();\n",
        "\n",
        "    float shared_time = 0;\n",
        "    cudaEventElapsedTime(&shared_time, start, stop);\n",
        "    printf(\"Shared Time: %.3f ms\\n\", shared_time);\n",
        "\n",
        "    printf(\"Speedup: %.2fx\\n\", naive_time / shared_time);\n",
        "\n",
        "    cudaFree(d_A); cudaFree(d_B); cudaFree(d_C);\n",
        "    return 0;\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V5BONWBxQDtt",
        "outputId": "b35e359a-7c7f-4f97-de67-02c28a22fe52"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing shared_memory.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile cpu_baseline.py\n",
        "import time\n",
        "import numpy as np\n",
        "\n",
        "def run_cpu_baseline():\n",
        "    # NPU Simulation Parameters (Week 1 Project)\n",
        "    # LLaMA-sized layer\n",
        "    M = 1       # Batch size (Edge Inference)\n",
        "    K = 4096    # Input Features\n",
        "    N = 4096    # Output Features\n",
        "\n",
        "    print(f\"Running CPU Baseline for Edge AI NPU Simulation...\")\n",
        "    print(f\"Dimensions: Input({M}x{K}) * Weights({K}x{N})\")\n",
        "\n",
        "    # Initialize data\n",
        "    X = np.random.randn(M, K).astype(np.float32)\n",
        "    W = np.random.randn(K, N).astype(np.float32)\n",
        "\n",
        "    # Measure Runtime\n",
        "    start_time = time.perf_counter()\n",
        "\n",
        "    # The actual NPU Operation\n",
        "    Y = np.dot(X, W)\n",
        "    Y = np.maximum(Y, 0) # ReLU\n",
        "\n",
        "    end_time = time.perf_counter()\n",
        "    duration_ms = (end_time - start_time) * 1000\n",
        "\n",
        "    print(f\"CPU Runtime: {duration_ms:.4f} ms\")\n",
        "    return duration_ms\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    run_cpu_baseline()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z0ecOYXtQFho",
        "outputId": "ef8489c1-0a60-430a-869f-926f2aa2b4e2"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing cpu_baseline.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "!nvcc -arch=sm_75 -o coalesced coalesced.cu\n",
        "!./coalesced\n",
        "!nvcc -arch=sm_75 -o non_coalesced non_coalesced.cu\n",
        "!./non_coalesced\n",
        "\n",
        "\n",
        "!nvcc -arch=sm_75 -o shared_memory shared_memory.cu\n",
        "!./shared_memory\n",
        "\n",
        "\n",
        "!python cpu_baseline.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-f7ijM6VQ60B",
        "outputId": "12ac45be-628d-442f-8366-d25e6ebe8de3"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Coalesced Access Time: 0.583 ms\n",
            "Effective Bandwidth: 230.10 GB/s\n",
            "Non-Coalesced (Stride 32) Time: 0.565 ms\n",
            "Effective Bandwidth: 7.43 GB/s\n",
            "Matrix Multiplication (N=2048)\n",
            "Naive Time: 53.718 ms\n",
            "Shared Time: 41.965 ms\n",
            "Speedup: 1.28x\n",
            "Running CPU Baseline for Edge AI NPU Simulation...\n",
            "Dimensions: Input(1x4096) * Weights(4096x4096)\n",
            "CPU Runtime: 4.5674 ms\n"
          ]
        }
      ]
    }
  ]
}